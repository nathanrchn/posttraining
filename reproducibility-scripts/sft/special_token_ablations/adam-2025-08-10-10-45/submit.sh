sbatch -N 64 -p large512 -t 12:00:00 -o reproducibility-scripts/sft/special_token_ablations/adam-2025-08-10-10-45/out/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs512-lr1e-05-epochs1-adam-apertus_mistral_only_between_roles.out -e reproducibility-scripts/sft/special_token_ablations/adam-2025-08-10-10-45/out/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs512-lr1e-05-epochs1-adam-apertus_mistral_only_between_roles.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_sft dataset=tulu3-sft-mixture-original-subset20 model=apertus-8b model_args.model_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix tokenizer_args.tokenizer_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix trainer=plw accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero2.yaml plw_args.prompt_loss_weight=0.0 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.learning_rate=1e-05 tokenizer_args.chat_template_name=apertus_mistral_only_between_roles training_args.num_train_epochs=1 artifacts_subdir=shared job_subdir=sp-token-ablation/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs512-lr1e-05-epochs1-adam-apertus_mistral_only_between_roles wandb.run_name=sp-token-ablation/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs512-lr1e-05-epochs1-adam-apertus_mistral_only_between_roles wandb.tags=[prod,plw,default,sp-token-ablation] resuming.resume=True 
sbatch -N 64 -p large512 -t 12:00:00 -o reproducibility-scripts/sft/special_token_ablations/adam-2025-08-10-10-45/out/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs512-lr1e-05-epochs1-adam-apertus_mistral_everywhere.out -e reproducibility-scripts/sft/special_token_ablations/adam-2025-08-10-10-45/out/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs512-lr1e-05-epochs1-adam-apertus_mistral_everywhere.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_sft dataset=tulu3-sft-mixture-original-subset20 model=apertus-8b model_args.model_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix tokenizer_args.tokenizer_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix trainer=plw accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero2.yaml plw_args.prompt_loss_weight=0.0 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.learning_rate=1e-05 tokenizer_args.chat_template_name=apertus_mistral_everywhere training_args.num_train_epochs=1 artifacts_subdir=shared job_subdir=sp-token-ablation/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs512-lr1e-05-epochs1-adam-apertus_mistral_everywhere wandb.run_name=sp-token-ablation/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs512-lr1e-05-epochs1-adam-apertus_mistral_everywhere wandb.tags=[prod,plw,default,sp-token-ablation] resuming.resume=True 
sbatch -N 64 -p large512 -t 12:00:00 -o reproducibility-scripts/sft/special_token_ablations/adam-2025-08-10-10-45/out/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs512-lr1e-05-epochs1-adam-apertus_mistral_everywhere_except_eos.out -e reproducibility-scripts/sft/special_token_ablations/adam-2025-08-10-10-45/out/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs512-lr1e-05-epochs1-adam-apertus_mistral_everywhere_except_eos.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_sft dataset=tulu3-sft-mixture-original-subset20 model=apertus-8b model_args.model_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix tokenizer_args.tokenizer_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix trainer=plw accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero2.yaml plw_args.prompt_loss_weight=0.0 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.learning_rate=1e-05 tokenizer_args.chat_template_name=apertus_mistral_everywhere_except_eos training_args.num_train_epochs=1 artifacts_subdir=shared job_subdir=sp-token-ablation/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs512-lr1e-05-epochs1-adam-apertus_mistral_everywhere_except_eos wandb.run_name=sp-token-ablation/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs512-lr1e-05-epochs1-adam-apertus_mistral_everywhere_except_eos wandb.tags=[prod,plw,default,sp-token-ablation] resuming.resume=True 
sbatch -N 64 -p large512 -t 12:00:00 -o reproducibility-scripts/sft/special_token_ablations/adam-2025-08-10-10-45/out/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs512-lr1e-05-epochs1-adam-apertus_mistral_beginning_of_message.out -e reproducibility-scripts/sft/special_token_ablations/adam-2025-08-10-10-45/out/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs512-lr1e-05-epochs1-adam-apertus_mistral_beginning_of_message.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_sft dataset=tulu3-sft-mixture-original-subset20 model=apertus-8b model_args.model_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix tokenizer_args.tokenizer_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix trainer=plw accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero2.yaml plw_args.prompt_loss_weight=0.0 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.learning_rate=1e-05 tokenizer_args.chat_template_name=apertus_mistral_beginning_of_message training_args.num_train_epochs=1 artifacts_subdir=shared job_subdir=sp-token-ablation/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs512-lr1e-05-epochs1-adam-apertus_mistral_beginning_of_message wandb.run_name=sp-token-ablation/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs512-lr1e-05-epochs1-adam-apertus_mistral_beginning_of_message wandb.tags=[prod,plw,default,sp-token-ablation] resuming.resume=True 
sbatch -N 64 -p large512 -t 12:00:00 -o reproducibility-scripts/sft/special_token_ablations/adam-2025-08-10-10-45/out/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs512-lr1e-05-epochs1-adam-apertus_mistral_asymmetric_assitant.out -e reproducibility-scripts/sft/special_token_ablations/adam-2025-08-10-10-45/out/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs512-lr1e-05-epochs1-adam-apertus_mistral_asymmetric_assitant.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_sft dataset=tulu3-sft-mixture-original-subset20 model=apertus-8b model_args.model_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix tokenizer_args.tokenizer_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix trainer=plw accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero2.yaml plw_args.prompt_loss_weight=0.0 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.learning_rate=1e-05 tokenizer_args.chat_template_name=apertus_mistral_asymmetric_assitant training_args.num_train_epochs=1 artifacts_subdir=shared job_subdir=sp-token-ablation/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs512-lr1e-05-epochs1-adam-apertus_mistral_asymmetric_assitant wandb.run_name=sp-token-ablation/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs512-lr1e-05-epochs1-adam-apertus_mistral_asymmetric_assitant wandb.tags=[prod,plw,default,sp-token-ablation] resuming.resume=True 
