sbatch -N 16 -p large512 -t 24:00:00 -o adam-2025-08-08-13-25/out/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs128-lr1e-05-epochs1-adam-apertus_chatml_no_special_tokens.out -e adam-2025-08-08-13-25/out/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs128-lr1e-05-epochs1-adam-apertus_chatml_no_special_tokens.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_sft dataset=tulu3-sft-mixture-original-subset20 model=apertus-8b model_args.model_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix tokenizer_args.tokenizer_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix trainer=plw accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero2.yaml plw_args.prompt_loss_weight=0.0 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.learning_rate=1e-05 tokenizer_args.chat_template_name=apertus_chatml_no_special_tokens training_args.num_train_epochs=1 artifacts_subdir=shared job_subdir=sp-token-ablation/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs128-lr1e-05-epochs1-adam-apertus_chatml_no_special_tokens wandb.run_name=sp-token-ablation/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs128-lr1e-05-epochs1-adam-apertus_chatml_no_special_tokens wandb.tags=[prod,plw,default,sp-token-ablation] resuming.resume=True 
sbatch -N 16 -p large512 -t 24:00:00 -o adam-2025-08-08-13-25/out/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs128-lr1e-05-epochs1-adam-apertus_chatml_special_tokens.out -e adam-2025-08-08-13-25/out/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs128-lr1e-05-epochs1-adam-apertus_chatml_special_tokens.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_sft dataset=tulu3-sft-mixture-original-subset20 model=apertus-8b model_args.model_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix tokenizer_args.tokenizer_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix trainer=plw accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero2.yaml plw_args.prompt_loss_weight=0.0 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.learning_rate=1e-05 tokenizer_args.chat_template_name=apertus_chatml_special_tokens training_args.num_train_epochs=1 artifacts_subdir=shared job_subdir=sp-token-ablation/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs128-lr1e-05-epochs1-adam-apertus_chatml_special_tokens wandb.run_name=sp-token-ablation/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs128-lr1e-05-epochs1-adam-apertus_chatml_special_tokens wandb.tags=[prod,plw,default,sp-token-ablation] resuming.resume=True 
sbatch -N 16 -p large512 -t 24:00:00 -o adam-2025-08-08-13-25/out/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs128-lr1e-05-epochs1-adam-apertus_mistral_no_special_tokens.out -e adam-2025-08-08-13-25/out/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs128-lr1e-05-epochs1-adam-apertus_mistral_no_special_tokens.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_sft dataset=tulu3-sft-mixture-original-subset20 model=apertus-8b model_args.model_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix tokenizer_args.tokenizer_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix trainer=plw accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero2.yaml plw_args.prompt_loss_weight=0.0 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.learning_rate=1e-05 tokenizer_args.chat_template_name=apertus_mistral_no_special_tokens training_args.num_train_epochs=1 artifacts_subdir=shared job_subdir=sp-token-ablation/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs128-lr1e-05-epochs1-adam-apertus_mistral_no_special_tokens wandb.run_name=sp-token-ablation/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs128-lr1e-05-epochs1-adam-apertus_mistral_no_special_tokens wandb.tags=[prod,plw,default,sp-token-ablation] resuming.resume=True 
sbatch -N 16 -p large512 -t 24:00:00 -o adam-2025-08-08-13-25/out/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs128-lr1e-05-epochs1-adam-apertus_mistral_special_tokens.out -e adam-2025-08-08-13-25/out/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs128-lr1e-05-epochs1-adam-apertus_mistral_special_tokens.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_sft dataset=tulu3-sft-mixture-original-subset20 model=apertus-8b model_args.model_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix tokenizer_args.tokenizer_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix trainer=plw accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero2.yaml plw_args.prompt_loss_weight=0.0 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.learning_rate=1e-05 tokenizer_args.chat_template_name=apertus_mistral_special_tokens training_args.num_train_epochs=1 artifacts_subdir=shared job_subdir=sp-token-ablation/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs128-lr1e-05-epochs1-adam-apertus_mistral_special_tokens wandb.run_name=sp-token-ablation/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs128-lr1e-05-epochs1-adam-apertus_mistral_special_tokens wandb.tags=[prod,plw,default,sp-token-ablation] resuming.resume=True 
sbatch -N 16 -p large512 -t 24:00:00 -o adam-2025-08-08-13-25/out/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs128-lr1e-05-epochs1-adam-apertus_xml_no_special_tokens.out -e adam-2025-08-08-13-25/out/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs128-lr1e-05-epochs1-adam-apertus_xml_no_special_tokens.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m swiss_alignment.train_sft dataset=tulu3-sft-mixture-original-subset20 model=apertus-8b model_args.model_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix tokenizer_args.tokenizer_name_or_path=/capstor/store/cscs/swissai/infra01/pretrain-checkpoints/apertus/Apertus8B-tokens7.2T-it1728000-hotfix trainer=plw accelerate_config=src/swiss_alignment/configs/accelerate/ds-zero2.yaml plw_args.prompt_loss_weight=0.0 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.learning_rate=1e-05 tokenizer_args.chat_template_name=apertus_xml_no_special_tokens training_args.num_train_epochs=1 artifacts_subdir=shared job_subdir=sp-token-ablation/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs128-lr1e-05-epochs1-adam-apertus_xml_no_special_tokens wandb.run_name=sp-token-ablation/Apertus8B-tokens7.2T-it1728000-hotfix-tulu3-sft-mixture-original-subset20-bs128-lr1e-05-epochs1-adam-apertus_xml_no_special_tokens wandb.tags=[prod,plw,default,sp-token-ablation] resuming.resume=True 
